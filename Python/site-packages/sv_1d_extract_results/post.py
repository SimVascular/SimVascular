# Copyright (c) Stanford University, The Regents of the University of
#               California, and others.
#
# All Rights Reserved.
#
# See Copyright-SimVascular.txt for additional details.
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject
# to the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
# IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
# TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
# PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER
# OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

"""

"""

import os
import re
import csv
import glob
import logging
import numpy as np
from collections import defaultdict
from scipy.interpolate import interp1d
from vtk.util.numpy_support import numpy_to_vtk as n2v
from vtk.util.numpy_support import vtk_to_numpy as v2n

from .manage import get_logger_name
from .solver import Solver
from .vtk_functions import read_geo, write_geo, add_array, collect_arrays, ClosestPoints, region_grow
import pdb

# get rid of numpy warnings
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"


class Post(object):
    def __init__(self, params, logger):
        self.params = params
        self.logger = logger

        # always read all segments
        self.params.all_segments = True

        # initialize results [result field][branch id][segment id][time step]
        self.results_1d = {}

        # read geometries
        self.logger.info(dir(self.params))
        
        geometries = {'1d': self.params.oned_model,
                      'cent': self.params.centerlines_file,
                      'surf': self.params.walls_mesh_file,
                      'vol': self.params.volume_mesh_file}

        self.geos = {}
        for name, pth in geometries.items():
            self.geos[name] = None
            if pth is not None:
                fpath = os.path.join(self.params.results_directory, pth)
                if os.path.exists(fpath):
                    self.geos[name] = read_geo(fpath)

    def process(self):
        self.read_results_1d()
        self.write_results_1d()
        if self.geos['1d'] is not None and self.geos['cent'] is not None:
            self.project_1d_to_centerline()
            if self.geos['surf'] is not None and self.geos['vol'] is not None:
                self.project_centerline_to_3d()

    def read_results_1d(self):
        """
        Read results from oneDSolver and store in dictionary [result field][branch id][segment id][time step]
        """
        for field in self.params.data_names:
            # list all output files for field
            result_list_1d = glob.glob(os.path.join(self.params.results_directory, '*branch*seg*_' + field + '.dat'))

            # loop segments
            self.results_1d[field] = defaultdict(dict)
            for f_res in result_list_1d:
                with open(f_res) as f:
                    reader = csv.reader(f, delimiter=' ')

                    # loop nodes
                    results_1d_f = []
                    for line in reader:
                        results_1d_f.append([float(l) for l in line if l][1:])

                # store results and GroupId
                seg = int(re.findall(r'\d+', f_res)[-1])
                branch = int(re.findall(r'\d+', f_res)[-2])
                self.results_1d[field][branch][seg] = np.array(results_1d_f)

    def write_results_1d(self):
        """
        Write 1D results as dictionary of numpy arrays to file
        """
        f_out = os.path.join(self.params.output_directory, self.params.output_file_name + '.npy')
        np.save(f_out, self.results_1d)

    def project_1d_to_centerline(self):
        """
        Project 1D results onto the centerline
        """
        # assemble output dict
        rec_dd = lambda: defaultdict(rec_dd)
        arrays = rec_dd()

        # extract point arrays from geometries
        arrays_cent = collect_arrays(self.geos['cent'].GetPointData())
        arrays_1d = collect_arrays(self.geos['1d'].GetPointData())

        # add centerline arrays
        for name, data in arrays_cent.items():
            arrays[name] = data

        # centerline points
        points = v2n(self.geos['cent'].GetPoints().GetData())

        # loop all result fields
        for f in self.params.data_names:
            array_f = np.zeros((arrays_cent['Path'].shape[0], len(self.params.times)))
            n_outlet = np.zeros(arrays_cent['Path'].shape[0])

            # loop all branches
            for br in self.results_1d[f].keys():
                # results of this branch
                res_br = self.results_1d[f][br]

                # get centerline path
                path_cent = arrays_cent['Path'][arrays_cent['BranchId'] == br]

                # get 1d path
                path_1d_geo = arrays_1d['Path'][arrays_1d['BranchId'] == br]

                # map results to branches
                path_1d_res, f_res = res_1d_to_path(path_1d_geo, res_br)

                # map 1d results to centerline using paths
                f_cent = interp1d(path_1d_res, f_res.T, fill_value='extrapolate')(path_cent).T

                # store results of this path
                array_f[arrays_cent['BranchId'] == br] = f_cent

                # add upstream part of branch within junction
                if br == 0:
                    continue

                # first point of branch
                ip = np.where(arrays_cent['BranchId'] == br)[0][0]

                # centerline that passes through branch (first occurence)
                cid = np.where(arrays_cent['CenterlineId'][ip])[0][0]

                # id of upstream junction
                jc = arrays_cent['BifurcationId'][ip - 1]

                # centerline within junction
                jc_cent = np.where(np.logical_and(arrays_cent['BifurcationId'] == jc, arrays_cent['CenterlineId'][:, cid]))[
                    0]

                # length of centerline within junction
                jc_path = np.append(0, np.cumsum(np.linalg.norm(np.diff(points[jc_cent], axis=0), axis=1)))
                jc_path /= jc_path[-1]

                # results at upstream branch
                res_br_u = self.results_1d[f][arrays_cent['BranchId'][jc_cent[0] - 1]]

                # results at beginning and end of centerline within junction
                f0 = res_br_u[sorted(res_br_u.keys())[-1]][-1]
                f1 = res_br[0][0]

                # map 1d results to centerline using paths
                array_f[jc_cent] += interp1d([0, 1], np.vstack((f0, f1)).T, fill_value='extrapolate')(jc_path).T

                # count number of outlets of this junction
                n_outlet[jc_cent] += 1

            # normalize by number of outlets
            array_f[n_outlet > 0] = (array_f[n_outlet > 0].T / n_outlet[n_outlet > 0]).T

            # assemble time steps
            for i, t in enumerate(self.params.times):
                arrays[f + '_' + str(t)] = array_f[:, i]

        for f, a in arrays.items():
            out_array = n2v(a)
            out_array.SetName(f)
            self.geos['cent'].GetPointData().AddArray(out_array)
        f_out = os.path.join(self.params.output_directory, self.params.output_file_name + '.vtp')
        write_geo(f_out, self.geos['cent'])

    def get_1d_3d_map(self):
        """
        Create a map from centerine to volume mesh through region growing
        """
        # get points
        points_vol = v2n(self.geos['vol'].GetPoints().GetData())
        points_1d = v2n(self.geos['cent'].GetPoints().GetData())

        # get volume points closest to centerline
        cp_vol = ClosestPoints(self.geos['vol'])
        seed_points = np.unique(cp_vol.search(points_1d))

        # map centerline points to selected volume points
        cp_1d = ClosestPoints(self.geos['cent'])
        seed_ids = np.array(cp_1d.search(points_vol[seed_points]))

        # call region growing algorithm
        ids, dist, rad = region_grow(self.geos['vol'], seed_points, seed_ids, self.logger, n_max=999)

        # check 1d to 3d map
        assert np.max(ids) <= self.geos['cent'].GetNumberOfPoints() - 1, '1d-3d map non-conforming'

        return ids, dist, rad

    def project_centerline_to_3d(self):
        """
        Map 1D results on centerline to volume mesh
        """
        # get 1d -> 3d map
        map_ids, map_iter, map_rad = self.get_1d_3d_map()

        # get arrays
        arrays_cent = collect_arrays(self.geos['cent'].GetPointData())

        # map all centerline arrays to volume geometry
        for name, array in arrays_cent.items():
            add_array(self.geos['vol'], name, array[map_ids])

        # add mapping to volume mesh
        for name, array in zip(['MapIds', 'MapIters'], [map_ids, map_iter]):
            add_array(self.geos['vol'], name, array)

        # inverse map
        map_ids_inv = {}
        for i in np.unique(map_ids):
            map_ids_inv[i] = np.where(map_ids == i)

        # create radial coordinate [0, 1]
        rad = np.zeros(self.geos['vol'].GetNumberOfPoints())
        for i, ids in map_ids_inv.items():
            rad_max = np.max(map_rad[ids])
            if rad_max == 0:
                rad_max = np.max(map_rad)
            rad[ids] = map_rad[ids] / rad_max
        add_array(self.geos['vol'], 'rad', rad)

        # set points at wall to hard 1
        wall_ids = collect_arrays(self.geos['surf'].GetPointData())['GlobalNodeID'].astype(int) - 1
        rad[wall_ids] = 1

        # mean velocity
        for a in arrays_cent.keys():
            if 'flow' in a:
                u_mean = arrays_cent[a] / arrays_cent['CenterlineSectionArea']

                # parabolic velocity
                u_quad = 2 * u_mean[map_ids] * (1 - rad ** 2)

                # scale parabolic flow profile to preserve mean flow
                for i, ids in map_ids_inv.items():
                    u_mean_is = np.mean(u_quad[map_ids_inv[i]])
                    u_quad[ids] *= u_mean[i] / u_mean_is

                # parabolic velocity vector field
                velocity = np.outer(u_quad, np.ones(3)) * arrays_cent['CenterlineSectionNormal'][map_ids]

                # add to volume mesh
                add_array(self.geos['vol'], a.replace('flow', 'velocity'), velocity)

        # write to file
        f_out = os.path.join(self.params.output_directory, self.params.output_file_name + '.vtu')
        write_geo(f_out, self.geos['vol'])


def res_1d_to_path(path, res):
    """
    Map 1D results to vessel path
    """
    path_1d = []
    int_1d = []
    for seg, res_1d_seg in sorted(res.items()):
        # 1d results are duplicate at FE-nodes at corners of segments
        if seg == 0:
            # start with first FE-node
            i_start = 0
        else:
            # skip first FE-node (equal to last FE-node of previous segment)
            i_start = 1

        # generate path for segment FEs, assuming equidistant spacing
        p0 = path[seg]
        p1 = path[seg + 1]
        path_1d += np.linspace(p0, p1, res_1d_seg.shape[0])[i_start:].tolist()
        int_1d += res_1d_seg[i_start:].tolist()

    return np.array(path_1d), np.array(int_1d)
